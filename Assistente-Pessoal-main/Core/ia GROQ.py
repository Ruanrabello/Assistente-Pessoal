from groq import Groq                             #? ğŸ“Œ Importa a classe groq que Ã© responsÃ¡vel por fazer chamadas para o endpoint
from Config.keys import GROQ_API_KEY              #? ğŸ“Œ Esta importando a variavel/chave do arquivo ja criado da past config
from Core.Personalidade import SYSTEM_PROMPT

client = Groq(api_key= GROQ_API_KEY)              #? ğŸ“Œ Equivale a abrir a conexÃ£o para chamar a API.

def chamar_ia(mensagem, historico=None):          #? ğŸ“Œ funÃ§Ã£o que recebe o texto que o usuario digitou e a lista de mensagens anteriores
    if historico is None:                         #? ğŸ“Œ Se for a primeira vez chamando a funÃ§Ã£o, ainda nÃ£o existe histÃ³rico entap cria uma funÃ§Ã£o
        historico =[]

    mensagens_para_api = [{"role": "system", "content": SYSTEM_PROMPT}]         #? Criamos uma lista Nova para envio comeÃ§ando sempre coma personalidade
    mensagens_para_api.extend(historico)                                        #? Adicionamos todo o histÃ³rico da conversa (User + Assistant anteriores)
    mensagens_para_api.append({"role": "user", "content": mensagem})            #? # 3. Adicionamos a pergunta ATUAL do usuÃ¡rio

    resposta = client.chat.completions.create(          #! Chama o endpoint chat/completions
        model="llama-3.1-8b-instant",                   #! Passa o modelo
        messages=mensagens_para_api                     #! Envia as mensagens (histÃ³rico + nova)
    )

    texto = resposta.choices[0].message.content         #! Pega sÃ³ o texto que a IA gerou
    return texto


'''
 A resposta da Groq vem dentro de um array choices.
1-VocÃª pega a primeira resposta (0)
2-Depois pega o atributo message
3-E por fim pega somente o texto (content)

ğŸ’¡ Exemplo da estrutura real:
{
  "choices": [
    {
      "message": {
        "role": "assistant",
        "content": "OlÃ¡! Como posso ajudar?"
      }
    }
  ]
}
'''
    